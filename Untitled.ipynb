{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Problem: Semi supervised annotation\n",
    "Deep Learning is awesome, it has given wings to computer vision and object\n",
    "detection/classification. But generating enough training data still remains a challenge! it\n",
    "takes countless hours for somebody to manually draw boxes around birds and people so\n",
    "that they can be then used to train the model.\n",
    "Can you think of a better approach, what if the model is iteratively trained and it helps you\n",
    "during the annotation itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "Note: This is my rough approach I have decided. The project is yet to be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Inputs:\n",
    "- A Video to be Annotated\n",
    "- What classes of objects to be extracted and annotated? (Array Like: Say [Car, Bus, person,...])\n",
    "- Frames of Interest (FOI) means What percentage of frames to be taken into account from the video. Say there are 20 frames in the video supplied, and we say 80% to be taken. So the system will take 80% frames which will be equally and linearly spaced.\n",
    "\n",
    "Why am I deciding to keep FOI? Well for many videos with visually less content and movements can cause a lot of similar/redudant frames resulting in increase in data redudancy and Low quality of data corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Outputs:\n",
    "- The final output will be a base image and a text file of bounding box coordinates\n",
    "- This will be organised in a good directory Structure as explained below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "output       \n",
    "│\n",
    "└───Class_1\n",
    "│   │\n",
    "│   └───Base\n",
    "│   │   │   class_1_1.png\n",
    "│   │   │   class_1_2.png\n",
    "│   │   │   ...\n",
    "│   └───BBoxes\n",
    "│       │   class_1_1.txt\n",
    "│       │   class_1_2.txt\n",
    "│       │   ...\n",
    "│   \n",
    "└───Class_2\n",
    "│   │\n",
    "│   └───Base\n",
    "│   │   │   class_2_1.png\n",
    "│   │   │   class_2_2.png\n",
    "│   │   │   ...\n",
    "│   └───BBoxes\n",
    "│       │   class_2_1.txt\n",
    "│       │   class_2_2.txt\n",
    "│       │   ...\n",
    "│   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will Use Darknet Model with YOLO object detection which will output Bounding Boxes in array like form.\n",
    "Research paper will be linked later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Code:\n",
    "for frame in frames:\n",
    "\n",
    "    for bb in bbs:\n",
    "        \n",
    "        if class_num in class_nums: //if detected box is in choice user wants.\n",
    "            \n",
    "            check if folder exist:\n",
    "                \n",
    "                yes: save respected outputs\n",
    "                \n",
    "                no: make directory and save\n",
    "        else:\n",
    "            Dont care\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_names = os.listdir('../videos for annot/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NVR_ch1_main_20200207123000_20200207130000.asf',\n",
       " 'NVR_ch1_main_20200207140000_20200207143000.asf',\n",
       " 'trimmed.mp4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vid_path = '../videos for annot/'+vid_names[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../videos for annot/trimmed.mp4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap= cv2.VideoCapture(_vid_path)\n",
    "frames= []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret==False:\n",
    "        break\n",
    "    else:\n",
    "        frames.append(frame)\n",
    "frames=np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(689, 1080, 1920, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
